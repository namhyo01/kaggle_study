# The Big Data Combine Engineered by BattleFin
## Overview
		○ 뉴스 및 정서 데이터를 사용하여 주가의 단기 이동 예측	
		○ BattleFin이 설계한 Big Data Combine은 컴퓨터과학자가 모델을 통해 수익을 창출할 수 있는 엘리트 예측 분석 기술을 갖춘 신속한 적용, 실시간 테스트입니다.
		○ 경쟁의 첫 번째 단계는 예측 모델링 경쟁입니다. 이것은 참가자들이 RavenPack이 제공한 감정데이터를 사용하여 주가변동을 예측하는 모델을 개발하는 것입니다.
		○ 거래자, 분석가  투자자는 항상 가격 변동을 더 잘 예측할 수 있는 기술을 찾고 잇씁니다.
		○ 유가 증권의 증가 또는 감소 여부를 알면 거래자는 더 나은 투자 결정을 내리고 위험을 보다 효과적으로 관리할 수 있습니다.
		○ 이 경쟁은 재무 데이터를 사용하여 예측 모델을 만들 수 있는 재능을 가진 사람들을 식별하기 위해 고안되었습니다.
		○ 참가자들에게는 5분간격으로 주식가격변동을 보여주는 일일 거래 데이터가 제공되며 향후 2시간 동안의 화를 예측하도록 요청합니다.
		○ 예측 모델링 단계의 승자는 플로리다 마이애미의 실시간 "Big Data Combine" 시험에 초대됩니다. 마이애미에서 열리는 라이브 이벤트에서 최대 12명의 결선 진출자가 선발됩니다.
		○ 운이 좋은 소수는 그들의 예측모델을 전문 결정자와 참여한 청중에게 던질 것입니다.
		○ 그들은 기술적 배경이 아닌 개인 용어, 예측 모델 설명 및 금융에서 돈을 버는데 모델을 사용하는 방법을 세 가지 항목으로 표현하는데 단 3분밖에 걸리지 않습니다.
		○ 그들의 모델과 프리젠테이션이 결정자에게  깊은 인상을 주면 BattleFin 및 Deltix와 협력하여 예측모델을 거래 전략으로 전환할 수 있습니다.


## Evaluation
'''
	제출은 예측된 백분율 변화와 실제 백분율 변화 사이의 평균 절대 오차에 의해 평가됩니다.
'''
## Submission Format
'''
	각 줄은 주어진 Field에 대해 예측된 백분율 변화를 가져야 합니다. 헤더가 필요합니다. 정확한 형식을 보려면 샘플 제출을 참조.
	'''
FileId,O1,O2,O3,...,O198
201,0,0,0,...
202,0,0,0,...
...
510,0,0,0...

'''

## DATA
이 경쟁의 목표는 '향후 2시간에 금융상품의 변동을 예측하라'
	
	이 데이터는 거래일 동안 5분 간격으로 기록된 다양한 금융증권(총 198개)의 특징을 나타냅니다.
	부정 행위를 피하기 위해 기능 이름이나 특정 날짜가 제공되지 않습니다.
	
	Data.zip - 200일 training 일, 310일 testing 일 데이터.
	TrainLabels.csv - 200 교육 목표.
	sampleSubmisssion.csv - 제출 형식.
	
	O1, O2, O3 등의 각 변수(출력)은 유가 증권 가치의 백분율 변활르 나타냅니다. I1, I2, I3등의 각 변수(입력)는 기능을 나타냅니다. 이러한 익명화된 이름으로 표시되는 기본 유가증권 및 기능은 모든 파일에서 동일합니다. (예: O1은 항상 동일 주식임.)
	 
	각 거래일 내에 전날 종가와 비교한 상대적 백분율로 결과가 제공됩니다. 각 데이터 파일의 첫 번째 줄은 이전 닫기를 나타냅니다. 예를 들어, 보안이 전날 $1에서 닫히고 다음날 $2에서 열리면 첫번째 출력은 0, 100이 됩니다. 모든 출력 값은 전날 종가를 기준으로 계산됩니다. 각 파일 내의 타임스탬프는 다음과 같습니다.
	
	Line 1 = 전날 종가의 출력 및 입력 (4PM ET(동부표준시))
	Line 2 = 현재 영업일의 출력 및 입력 (9:30AM ET(동부표준시))
	Line 3 = 9:35 AM의 동부표준시
	…
	Line 55 = 55 Outputs and inputs at 1:55 PM ET(동부표준시)
	
	2시간 후 오후 4시 (ET) 에 출력을 예측하라는 메시지가 표시됩니다.


## Big Bear, Share your approach, 랭크 9위 
    @BigBear 폴더의 소스코드는 제가 실행되게 수정해둠.

    
	1. 기능 선택을 수행하려면, gbm(
	Gradient Boosting Algorithm
	출처: <https://3months.tistory.com/368> 
	)
	2. 을 사용. 그런다음 l1 손실로 선형회귀를 사용하면 Miroslaw의 코드를 찾을 수 있습니다. 이 방법은 간단합니다. 그러나 많은 시간이 소요됩니다. 기능선택을 수행하려면 20개의 스레드가 있는 서버에서 약 24시간이 소요됩니다. 그러나 16개의 코어, 32개의 스레드가 있는 서버가 있습니다. 그래서 괜찮습니다. 기능 선택 결과를 업로드했습니다. 직접 다운로드하여 출력 디렉토리에 넣을 수 있습니다.
	3. 다른 모델을 사용하면 ar 모델로 말할 수 있습니까? 이것은 또한 Miroslaw의 공유에서 비롯됩니다. 방법을 다음과 같이 정의했습니다.
	p = a0 * x0 + (1-a0)*a1*x1 + (1-a0)(1-a1)a2*x2 + ... + (1-a0)(1-a1)...(1-an-1) an xn + b.
	
	출처: <https://www.kaggle.com/c/battlefin-s-big-data-combine-forecasting-challenge/discussion/5966#latest-120239> 
	
	함수를 최소화하려면 비용과 기울기를 정의해야합니다. 내 코드를 참조할 수 있습니다. 이 방법은 매우 효율적이며 몇 분만 소요됩니다. 개인 점수에서 이 모델도 더 좋습니다. 
	첫 번째 접근 방식의 공개 점수 : 0.41820 개인점수 : 0.42668
	두 번째 방법으로 공개 점수 : 0.41833 개인 점수 : 0.42532
	
	To run the code:
	mkdir data, output, res
	python2 dataProcess.py
	python2 model linr se
	python2 model ar
	
	출처: <https://www.kaggle.com/c/battlefin-s-big-data-combine-forecasting-challenge/discussion/5966#latest-120239> 
	

## 	@BreakfastPirate, 랭크5위
	1. 가격변동상관법에 따라 유가증권을 그룹화
	2. 각 보안그룹에 대해 I146을 사용하여 "결정 그루터기"
	각 리프 노드에 대해 Prediction = m * Last Observed Value 형식의 모델을 빌드하십시오. 각 리프 노드에 대해 MAE를 최소화하는 m을 찾으십시오. m = 1.0과 관련하여 MAE가 가장 개선되거나 가장 많이 손실 된 행은 포함되지 않았습니다.
	
	출처: <https://www.kaggle.com/c/battlefin-s-big-data-combine-forecasting-challenge/discussion/5966#latest-120239> 
	


